{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of practice_approx_qlearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehaRima/2sxc-content-app/blob/master/Copy_of_practice_approx_qlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAyDN1OLj1Ix",
        "colab_type": "text"
      },
      "source": [
        "# Approximate q-learning\n",
        "\n",
        "In this notebook you will teach a __tensorflow__ neural network to do Q-learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFuL-kvDj1Iz",
        "colab_type": "text"
      },
      "source": [
        "__Frameworks__ - we'll accept this homework in any deep learning framework. This particular notebook was designed for tensorflow, but you will find it easy to adapt it to almost any python-based deep learning framework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ilT6g9Hj4O-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75adc2bf-6632-4561-9fa6-9a541c1968d7"
      },
      "source": [
        "!pip install matplotlib-venn\n",
        "!apt-get -qq install -y libfluidsynth1\n",
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the current version: \n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# For a specific version:\n",
        "!pip install tensorflow==1.2\n",
        "\n",
        "# For the latest nightly build:\n",
        "!pip install tf-nightly\n",
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive\n",
        "!apt-get -qq install python-cartopy python3-cartopy\n",
        "import cartopy\n",
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.6/dist-packages (0.11.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from matplotlib-venn) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from matplotlib-venn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from matplotlib-venn) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->matplotlib-venn) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->matplotlib-venn) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->matplotlib-venn) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->matplotlib-venn) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->matplotlib-venn) (1.15.0)\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "(Reading database ... 144579 files and directories currently installed.)\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Name: tensorflow\n",
            "Version: 2.3.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: grpcio, absl-py, opt-einsum, numpy, wrapt, tensorflow-estimator, six, protobuf, wheel, scipy, termcolor, h5py, gast, keras-preprocessing, tensorboard, google-pasta, astunparse\n",
            "Required-by: fancyimpute\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (49.6.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Collecting tensorflow==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/55/7995cc1e9e60fa37ea90e6777d832e75026fde5c6109215d892aaff2e9b7/tensorflow-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K     |████████████████████████████████| 35.0MB 117kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (3.12.4)\n",
            "Collecting backports.weakref==1.0rc1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Collecting markdown==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 37.8MB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.18.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2) (49.6.0)\n",
            "Building wheels for collected packages: markdown, html5lib\n",
            "  Building wheel for markdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markdown: filename=Markdown-2.2.0-cp36-none-any.whl size=136261 sha256=7e9ec87ea169a7b6628a3bd8e2a7372fa223e67d0ecb3e1d23be2aea4d47ee9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=bd4ae2e4fac43067ac838a1538b08223c0d3f29a22b84393e7db56b74b0b87f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built markdown html5lib\n",
            "\u001b[31mERROR: tensorboard 2.3.0 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: backports.weakref, markdown, html5lib, bleach, tensorflow\n",
            "  Found existing installation: Markdown 3.2.2\n",
            "    Uninstalling Markdown-3.2.2:\n",
            "      Successfully uninstalled Markdown-3.2.2\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.5\n",
            "    Uninstalling bleach-3.1.5:\n",
            "      Successfully uninstalled bleach-3.1.5\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-1.2.0\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/d5/adae781540cc01d11d4680748a313ea82ec76618ad4215b49ac6e8a434eb/tf_nightly-2.4.0.dev20200828-cp36-cp36m-manylinux2010_x86_64.whl (345.8MB)\n",
            "\u001b[K     |████████████████████████████████| 345.8MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.12.4)\n",
            "Collecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/61/13f5ec767adf1c22f7f5a9acc7aea806a93b36312d6aa586d89265eef14b/tf_estimator_nightly-2.4.0.dev2020082801-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Collecting flatbuffers>=1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.31.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.35.1)\n",
            "Collecting tb-nightly<3.0.0a0,>=2.4.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/ad/ebedea2799f4742201ff0c252c05f3b4df856efcb6b80390be163b9e3e1d/tb_nightly-2.4.0a20200828-py3-none-any.whl (8.9MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9MB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tf-nightly) (49.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
            "Collecting markdown>=2.6.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 1.2.0 has requirement markdown==2.2.0, but you'll have markdown 3.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tf-estimator-nightly, flatbuffers, markdown, tb-nightly, tf-nightly\n",
            "  Found existing installation: Markdown 2.2.0\n",
            "    Uninstalling Markdown-2.2.0:\n",
            "      Successfully uninstalled Markdown-2.2.0\n",
            "Successfully installed flatbuffers-1.12 markdown-3.2.2 tb-nightly-2.4.0a20200828 tf-estimator-nightly-2.4.0.dev2020082801 tf-nightly-2.4.0.dev20200828\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 144584 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.2.2-3.1ubuntu0.6_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.2.2-3.1ubuntu0.6) ...\n",
            "Setting up libarchive-dev:amd64 (3.2.2-3.1ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting libarchive\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/d4/26f5c9835d4d648e4f22b5fb91288457698e928aaf9d4ab7eff405b7ef03/libarchive-0.4.7.tar.gz\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 8.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libarchive: filename=libarchive-0.4.7-cp36-none-any.whl size=31632 sha256=8f7c055cb7cf2baa4de118a0bf5defa6a6604dd6f9d8535707c802e067ad6d85\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/5c/fa/92ee330d259e8fa5bedbd53f67040710fe81cfa463b8711d26\n",
            "Successfully built libarchive\n",
            "Installing collected packages: nose, libarchive\n",
            "Successfully installed libarchive-0.4.7 nose-1.3.7\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "(Reading database ... 144640 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-pyshp.\n",
            "Preparing to unpack .../1-python-pyshp_1.2.12+ds-1_all.deb ...\n",
            "Unpacking python-pyshp (1.2.12+ds-1) ...\n",
            "Selecting previously unselected package python-shapely.\n",
            "Preparing to unpack .../2-python-shapely_1.6.4-1_amd64.deb ...\n",
            "Unpacking python-shapely (1.6.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cartopy:amd64.\n",
            "Preparing to unpack .../4-python-cartopy_0.14.2+dfsg1-2build3_amd64.deb ...\n",
            "Unpacking python-cartopy:amd64 (0.14.2+dfsg1-2build3) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../5-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-pyshp.\n",
            "Preparing to unpack .../6-python3-pyshp_1.2.12+ds-1_all.deb ...\n",
            "Unpacking python3-pyshp (1.2.12+ds-1) ...\n",
            "Selecting previously unselected package python3-shapely.\n",
            "Preparing to unpack .../7-python3-shapely_1.6.4-1_amd64.deb ...\n",
            "Unpacking python3-shapely (1.6.4-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../8-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cartopy:amd64.\n",
            "Preparing to unpack .../9-python3-cartopy_0.14.2+dfsg1-2build3_amd64.deb ...\n",
            "Unpacking python3-cartopy:amd64 (0.14.2+dfsg1-2build3) ...\n",
            "Setting up python-shapely (1.6.4-1) ...\n",
            "Setting up python-pyshp (1.2.12+ds-1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-shapely (1.6.4-1) ...\n",
            "Setting up python3-pyshp (1.2.12+ds-1) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python3-cartopy:amd64 (0.14.2+dfsg1-2build3) ...\n",
            "Setting up python-cartopy:amd64 (0.14.2+dfsg1-2build3) ...\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4qXalAcj1I3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fb42fdce-059d-4a4d-82cb-c94245566fcc"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    %tensorflow_version 1.x\n",
        "    \n",
        "    if not os.path.exists('.setup_complete'):\n",
        "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring20/setup_colab.sh -O- | bash\n",
        "\n",
        "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week4_approx/submit.py\n",
        "\n",
        "        !touch .setup_complete\n",
        "\n",
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "        \n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/atari_wrappers.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/utils.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/replay_buffer.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/framebuffer.py\n",
        "\n",
        "    !pip install gym[box2d]\n",
        "\n",
        "    !touch .setup_complete        \n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 145232 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnUPW2xpj1JB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e4061cbb-f66d-4034-f8df-4ca1cd6ef0bf"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "!pip install utils\n",
        "import utils\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading https://files.pythonhosted.org/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHmqTyzpj1JI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "db384947-c644-413b-dddf-9ea947d57c9a"
      },
      "source": [
        "env = gym.make(\"CartPole-v0\").env\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "plt.imshow(env.render(\"rgb_array\"))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f73a309ff28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guthxLfYj1JM",
        "colab_type": "text"
      },
      "source": [
        "# Approximate (deep) Q-learning: building the network\n",
        "\n",
        "To train a neural network policy one must have a neural network policy. Let's build it.\n",
        "\n",
        "\n",
        "Since we're working with a pre-extracted features (cart positions, angles and velocities), we don't need a complicated network yet. In fact, let's build something like this for starters:\n",
        "\n",
        "![img](https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/yet_another_week/_resource/qlearning_scheme.png)\n",
        "\n",
        "For your first run, please only use linear layers (`L.Dense`) and activations. Stuff like batch normalization or dropout may ruin everything if used haphazardly. \n",
        "\n",
        "Also please avoid using nonlinearities like sigmoid & tanh: since agent's observations are not normalized, sigmoids might be saturated at initialization. Instead, use non-saturating nonlinearities like ReLU.\n",
        "\n",
        "Ideally you should start small with maybe 1-2 hidden layers with < 200 neurons and then increase network size if agent doesn't beat the target score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niMDulVUq2Yq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e295a196-bd6a-4f14-ee01-2b744bca0f52"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as L\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()\n",
        "keras.backend.set_session(sess)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3RrWLcj1JS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a5267567-1ad3-498c-8927-81ac9877f9f6"
      },
      "source": [
        "network = keras.models.Sequential()\n",
        "network.add(L.InputLayer(state_dim))\n",
        "\n",
        "# let's create a network for approximate q-learning following guidelines above\n",
        "# Hidden layers\n",
        "network.add(L.Dense(200, activation=\"relu\"))\n",
        "network.add(L.Dense(200, activation=\"relu\"))\n",
        "\n",
        "# Output layer (n_actions output)\n",
        "network.add(L.Dense(n_actions, activation=\"linear\"))\n",
        "\n",
        "# <YOUR CODE: stack more layers!!!1 >"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq4ZzotFj1JZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_action(state, epsilon=0):\n",
        "    \"\"\"\n",
        "    sample actions with epsilon-greedy policy\n",
        "    recap: with p = epsilon pick random action, else pick action with highest Q(s,a)\n",
        "    \"\"\"\n",
        "    \n",
        "    if random.uniform(0,1) < epsilon:\n",
        "        # Choose action randomly\n",
        "        return random.randrange(n_actions)\n",
        "    else:        \n",
        "        q_values = network.predict(state[None])[0]\n",
        "        # q_values = network.predict(state)[0]\n",
        "        return np.argmax(q_values)\n",
        "    ###YOUR CODE\n",
        "\n",
        "#     return <epsilon-greedily selected action>"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXHzrjUNj1Je",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1a13d0bf-72f4-4f51-c102-d889690267ae"
      },
      "source": [
        "assert network.output_shape == (None, n_actions), \"please make sure your model maps state s -> [Q(s,a0), ..., Q(s, a_last)]\"\n",
        "assert network.layers[-1].activation == keras.activations.linear, \"please make sure you predict q-values without nonlinearity\"\n",
        "\n",
        "# test epsilon-greedy exploration\n",
        "s = env.reset()\n",
        "assert np.shape(get_action(s)) == (), \"please return just one action (integer)\"\n",
        "for eps in [0., 0.1, 0.5, 1.0]:\n",
        "    state_frequencies = np.bincount([get_action(s, epsilon=eps) for i in range(10000)], minlength=n_actions)\n",
        "    best_action = state_frequencies.argmax()\n",
        "    assert abs(state_frequencies[best_action] - 10000 * (1 - eps + eps / n_actions)) < 200\n",
        "    for other_action in range(n_actions):\n",
        "        if other_action != best_action:\n",
        "            assert abs(state_frequencies[other_action] - 10000 * (eps / n_actions)) < 200\n",
        "    print('e=%.1f tests passed'%eps)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "e=0.0 tests passed\n",
            "e=0.1 tests passed\n",
            "e=0.5 tests passed\n",
            "e=1.0 tests passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbjU9erOj1Jl",
        "colab_type": "text"
      },
      "source": [
        "### Q-learning via gradient descent\n",
        "\n",
        "We shall now train our agent's Q-function by minimizing the TD loss:\n",
        "$$ L = { 1 \\over N} \\sum_i (Q_{\\theta}(s,a) - [r(s,a) + \\gamma \\cdot max_{a'} Q_{-}(s', a')]) ^2 $$\n",
        "\n",
        "\n",
        "Where\n",
        "* $s, a, r, s'$ are current state, action, reward and next state respectively\n",
        "* $\\gamma$ is a discount factor defined two cells above.\n",
        "\n",
        "The tricky part is with  $Q_{-}(s',a')$. From an engineering standpoint, it's the same as $Q_{\\theta}$ - the output of your neural network policy. However, when doing gradient descent, __we won't propagate gradients through it__ to make training more stable (see lectures).\n",
        "\n",
        "To do so, we shall use `tf.stop_gradient` function which basically says \"consider this thing constant when doingbackprop\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSqTOS3Jj1Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create placeholders for the <s, a, r, s'> tuple and a special indicator for game end (is_done = True)\n",
        "states_ph = keras.backend.placeholder(dtype='float32', shape=(None,) + state_dim)\n",
        "actions_ph = keras.backend.placeholder(dtype='int32', shape=[None])\n",
        "rewards_ph = keras.backend.placeholder(dtype='float32', shape=[None])\n",
        "next_states_ph = keras.backend.placeholder(dtype='float32', shape=(None,) + state_dim)\n",
        "is_done_ph = keras.backend.placeholder(dtype='bool', shape=[None])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZZQw7-Yj1Ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get q-values for all actions in current states\n",
        "predicted_qvalues = network(states_ph)\n",
        "\n",
        "#select q-values for chosen actions\n",
        "predicted_qvalues_for_actions = tf.reduce_sum(predicted_qvalues * tf.one_hot(actions_ph, n_actions), axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbCN380Bj1Jy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5e5f3234-fde9-4f69-b24d-d5e64c829db8"
      },
      "source": [
        "gamma = 0.99\n",
        "\n",
        "# compute q-values for all actions in next states\n",
        "predicted_next_qvalues = network(next_states_ph)\n",
        "# <YOUR CODE - apply network to get q-values for next_states_ph>\n",
        "\n",
        "# compute V*(next_states) using predicted next q-values\n",
        "next_state_values = tf.reduce_max(predicted_next_qvalues, axis=1)\n",
        "# <YOUR CODE>\n",
        "\n",
        "# compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
        "target_qvalues_for_actions = rewards_ph + gamma * next_state_values\n",
        "# <YOUR CODE>\n",
        "\n",
        "# at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
        "target_qvalues_for_actions = tf.where(is_done_ph, rewards_ph, target_qvalues_for_actions)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-5d6ac35c0e6b>:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOxhdVj_j1KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mean squared error loss to minimize\n",
        "loss = (predicted_qvalues_for_actions - tf.stop_gradient(target_qvalues_for_actions)) ** 2\n",
        "loss = tf.reduce_mean(loss)\n",
        "\n",
        "# training function that resembles agent.update(state, action, reward, next_state) from tabular agent\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHd82L-Zj1K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert tf.gradients(loss, [predicted_qvalues_for_actions])[0] is not None, \"make sure you update q-values for chosen actions and not just all actions\"\n",
        "assert tf.gradients(loss, [predicted_next_qvalues])[0] is None, \"make sure you don't propagate gradient w.r.t. Q_(s',a')\"\n",
        "assert predicted_next_qvalues.shape.ndims == 2, \"make sure you predicted q-values for all actions in next state\"\n",
        "assert next_state_values.shape.ndims == 1, \"make sure you computed V(s') as maximum over just the actions axis and not all axes\"\n",
        "assert target_qvalues_for_actions.shape.ndims == 1, \"there's something wrong with target q-values, they must be a vector\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWu4lRLoj1LC",
        "colab_type": "text"
      },
      "source": [
        "### Playing the game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAAl8ZXkj1LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beMxwBVfj1LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_session(env, t_max=1000, epsilon=0, train=False):\n",
        "    \"\"\"play env with approximate q-learning agent and train it at the same time\"\"\"\n",
        "    total_reward = 0\n",
        "    s = env.reset()\n",
        "    \n",
        "    for t in range(t_max):\n",
        "        a = get_action(s, epsilon=epsilon)       \n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        \n",
        "        if train:\n",
        "            sess.run(train_step,{\n",
        "                states_ph: [s], actions_ph: [a], rewards_ph: [r], \n",
        "                next_states_ph: [next_s], is_done_ph: [done]\n",
        "            })\n",
        "\n",
        "        total_reward += r\n",
        "        s = next_s\n",
        "        if done:\n",
        "            break\n",
        "            \n",
        "    return total_reward"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AT06hJDj1Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon = 0.5"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdr3uV60j1Lt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "511b4110-fd60-4505-91e2-13d9d487e4e5"
      },
      "source": [
        "for i in range(1000):\n",
        "    session_rewards = [generate_session(env, epsilon=epsilon, train=True) for _ in range(100)]\n",
        "    print(\"epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\".format(i, np.mean(session_rewards), epsilon))\n",
        "    \n",
        "    epsilon *= 0.99\n",
        "    assert epsilon >= 1e-4, \"Make sure epsilon is always nonzero during training\"\n",
        "    \n",
        "    if np.mean(session_rewards) > 300:\n",
        "        print(\"You Win!\")\n",
        "        break"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch #0\tmean reward = 14.580\tepsilon = 0.500\n",
            "epoch #1\tmean reward = 15.520\tepsilon = 0.495\n",
            "epoch #2\tmean reward = 14.210\tepsilon = 0.490\n",
            "epoch #3\tmean reward = 15.400\tepsilon = 0.485\n",
            "epoch #4\tmean reward = 13.480\tepsilon = 0.480\n",
            "epoch #5\tmean reward = 21.480\tepsilon = 0.475\n",
            "epoch #6\tmean reward = 26.040\tepsilon = 0.471\n",
            "epoch #7\tmean reward = 35.150\tepsilon = 0.466\n",
            "epoch #8\tmean reward = 32.120\tepsilon = 0.461\n",
            "epoch #9\tmean reward = 43.840\tepsilon = 0.457\n",
            "epoch #10\tmean reward = 62.550\tepsilon = 0.452\n",
            "epoch #11\tmean reward = 84.270\tepsilon = 0.448\n",
            "epoch #12\tmean reward = 105.980\tepsilon = 0.443\n",
            "epoch #13\tmean reward = 126.330\tepsilon = 0.439\n",
            "epoch #14\tmean reward = 129.030\tepsilon = 0.434\n",
            "epoch #15\tmean reward = 158.440\tepsilon = 0.430\n",
            "epoch #16\tmean reward = 160.840\tepsilon = 0.426\n",
            "epoch #17\tmean reward = 190.460\tepsilon = 0.421\n",
            "epoch #18\tmean reward = 174.350\tepsilon = 0.417\n",
            "epoch #19\tmean reward = 230.570\tepsilon = 0.413\n",
            "epoch #20\tmean reward = 230.500\tepsilon = 0.409\n",
            "epoch #21\tmean reward = 264.870\tepsilon = 0.405\n",
            "epoch #22\tmean reward = 247.540\tepsilon = 0.401\n",
            "epoch #23\tmean reward = 244.900\tepsilon = 0.397\n",
            "epoch #24\tmean reward = 314.040\tepsilon = 0.393\n",
            "You Win!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-m8-pXyj1Ly",
        "colab_type": "text"
      },
      "source": [
        "### How to interpret results\n",
        "\n",
        "\n",
        "Welcome to the f.. world of deep f...n reinforcement learning. Don't expect agent's reward to smoothly go up. Hope for it to go increase eventually. If it deems you worthy.\n",
        "\n",
        "Seriously though,\n",
        "* __ mean reward__ is the average reward per game. For a correct implementation it may stay low for some 10 epochs, then start growing while oscilating insanely and converges by ~50-100 steps depending on the network architecture. \n",
        "* If it never reaches target score by the end of for loop, try increasing the number of hidden neurons or look at the epsilon.\n",
        "* __ epsilon__ - agent's willingness to explore. If you see that agent's already at < 0.01 epsilon before it's is at least 200, just reset it back to 0.1 - 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGvEKSZpj1Ly",
        "colab_type": "text"
      },
      "source": [
        "### Record videos\n",
        "\n",
        "As usual, we now use `gym.wrappers.Monitor` to record a video of our agent playing the game. Unlike our previous attempts with state binarization, this time we expect our agent to act ~~(or fail)~~ more smoothly since there's no more binarization error at play.\n",
        "\n",
        "As you already did with tabular q-learning, we set epsilon=0 for final evaluation to prevent agent from exploring himself to death."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjZaW1fCj1Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Record sessions\n",
        "\n",
        "import gym.wrappers\n",
        "\n",
        "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
        "    sessions = [generate_session(env_monitor, epsilon=0, train=False) for _ in range(100)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObJvQFNRj1L_",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/videos/openaigym.video.0.104.video000064.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "d2f0ac3c-f5b6-46fe-fbe8-f9bcf223fa75"
      },
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(video_names[-1]))  # You can also try other indices"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"480\" controls>\n",
              "  <source src=\"videos/openaigym.video.0.104.video000064.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6sHgjCnj1ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROkdLAQsj1MH",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwHoWDN0j1MI",
        "colab_type": "text"
      },
      "source": [
        "### Submit to coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsCCenKJj1MJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "43081e99-0f31-4c25-c9cb-0d56a45d112b"
      },
      "source": [
        "from submit import submit_cartpole\n",
        "submit_cartpole(generate_session, 'sahelirima23@gmail.com', 'PNKUghYSLDu0CrzW')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your average reward is 479.26 over 100 episodes\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}